FROM python:3.11-slim-buster

WORKDIR /app

RUN apt-get update && apt-get install -y \
    openjdk-11-jdk \
    wget \
    unzip \
    curl \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Set Java home environment variable
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Install Spark
ENV SPARK_VERSION=3.5.3
ENV HADOOP_VERSION=3
RUN wget https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz \
    && tar -xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz \
    && mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark \
    && rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz

# Set Spark environment variables
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH
ENV PYSPARK_PYTHON=python3

COPY requirements.txt requirements.txt
# RUN pip install -r requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

RUN mkdir -p /app/model
COPY clientApp.py .
COPY model /app/model

COPY clientApp.py .

COPY TrainingDataset.csv .

# Default command for running the prediction script
ENTRYPOINT ["python", "/app/clientApp.py", "/data/data.csv", "/app/model"]
